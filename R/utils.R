#' summarise a data frame `d` by groups along a `variable`
#' @param d tibble data frame
#' @param ... group_by variables
#' @param variable string
#'
#'
#' @return Data frame containing sample quantiles at probabilities 0.05, 0.25, 0.50,
#' 0.75 and 0.95
create_quantiles <- function(d, ..., variable = NULL) {
  d %>%
    dplyr::group_by(...) %>%
    dplyr::summarise(
      p50 = stats::quantile(.data[[variable]], 0.5),
      p10 = stats::quantile(.data[[variable]], 0.1),
      p25 = stats::quantile(.data[[variable]], 0.25),
      p75 = stats::quantile(.data[[variable]], 0.75),
      p90 = stats::quantile(.data[[variable]], 0.9),
      p025 = stats::quantile(.data[[variable]], 0.025),
      p975 = stats::quantile(.data[[variable]], 0.975),
      min_sim = min(.data[[variable]]),
      max_sim = max(.data[[variable]])
    )
}

#' Summarise incidence values into weekly aggregate
#' @param samples Daily samples generated from \code{generate_forecasts}
#'
#' @return Data-frame of aggregated weekly forecast samples for each simulation run
#' \describe{
#'   \item{week_date}{last date of week over which daily samples were aggregated}
#'   \item{daily_sim}{simulation run number}
#'   \item{weekly_value}{projected number of daily confirmed cases aggregated by week}
#' }
extract_agg_samples_epiestim_fit <- function(samples) {
  daily_incidence <- week_date <- sim <- daily_date <- NULL
  samples <- samples %>%
    dplyr::mutate(week_date = lubridate::floor_date(daily_date, unit = "weeks")) %>%
    dplyr::group_by(week_date, sim) %>%
    dplyr::summarise(weekly_incidence = sum(daily_incidence), .groups = "keep")

  return(samples)
}


#' Extract calculated quantiles from the weekly samples
#'
#' @param tp element from list output generated by \code{forecast_time_period}
#'
extract_quantile_epiestim <- function(tp) {
  dat_quantiles <-
    tibble::tibble(
      quantile_date = tp$quantile_date,
      p50 = tp$p50,
      p25 = tp$p25,
      p75 = tp$p75,
      p025 = tp$p025,
      p975 = tp$p975,
      min_sim = tp$min_sim,
      max_sim = tp$max_sim
    )
  return(dat_quantiles)
}




# Extract simulated samples

#' Extract simulated samples ideally 1000 samples per date
#'
#' @param tp element from list output generated by \code{forecast_time_period}
#' @param aggregate_unit Time forecasted samples are aggregated by (weekly or daily)
#'
extract_sim_samples_epiestim <- function(tp, aggregate_unit = NULL) {
  if (aggregate_unit == "weekly") {
    dat_samples <- tibble::tibble(
      quantile_date = tp$week_date,
      value = tp$weekly_incidence
    )
  } else if (aggregate_unit == "daily") {
    dat_samples <- tibble::tibble(
      quantile_date = tp$daily_date,
      value = tp$daily_incidence
    )
  }
  return(dat_samples)
}



#' Helper function to plot forecasts at each iteration with uncertainty quantile ranges
#'
#'
#' @param  cur_time_period_result element from list output generated by \code{forecast_time_period_epiestim}
#'
#' @return Plot displaying forecast for one time period
plot_all_time_period_forecast_data_helper <- function(cur_time_period_result) {
  p025 <- p975 <- p25 <- p75 <- p50 <- confirm <- incidence <- NULL
  model_data <- tibble::tibble(
    date = cur_time_period_result$model_data_date,
    confirm = cur_time_period_result$confirm
  )

  model_data <- model_data %>%
    filter(date > date[which.max(date) - 20])

  aggregate_unit <- cur_time_period_result$quantile_unit
  if (aggregate_unit == "weekly") {
    data_proj <- tibble::tibble(
      date = cur_time_period_result$week_date,
      sim = cur_time_period_result$sim,
      incidence = cur_time_period_result$weekly_incidence
    )
    p <- data_proj %>%
      dplyr::mutate(incidence = incidence) %>%
      create_quantiles(date, variable = "incidence") %>%
      ggplot2::ggplot(ggplot2::aes(x = date)) +
      ggplot2::theme_bw() +
      ggplot2::geom_ribbon(ggplot2::aes(ymin = p025, ymax = p975), fill = "#08519C", alpha = 0.25) +
      ggplot2::geom_ribbon(ggplot2::aes(ymin = p25, ymax = p75), fill = "#08519C", alpha = 0.25) +
      ggplot2::geom_line(ggplot2::aes(y = p50), color = "#08519C") +
      ggplot2::geom_point(ggplot2::aes(x = date, y = confirm), data = model_data) +
      ggplot2::scale_x_date(date_breaks = "1 week", date_labels = "%b %d") +
      ggplot2::theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      ggplot2::labs(
        x = "Time", y = paste("Weekly projection of confirmed \ncases starting from", max(cur_time_period_result$model_data_date), sep = " "),
        fill = "", color = ""
      )
  } else if (aggregate_unit == "daily") {
    data_proj <- tibble::tibble(
      date = cur_time_period_result$daily_date,
      sim = cur_time_period_result$sim,
      incidence = cur_time_period_result$daily_incidence
    )
    p <- data_proj %>%
      dplyr::mutate(incidence = incidence) %>%
      create_quantiles(date, variable = "incidence") %>%
      ggplot2::ggplot(ggplot2::aes(x = date)) +
      ggplot2::theme_bw() +
      ggplot2::geom_ribbon(ggplot2::aes(ymin = p025, ymax = p975), fill = "#08519C", alpha = 0.25) +
      ggplot2::geom_ribbon(ggplot2::aes(ymin = p25, ymax = p75), fill = "#08519C", alpha = 0.25) +
      ggplot2::geom_line(ggplot2::aes(y = p50), color = "#08519C") +
      ggplot2::geom_point(ggplot2::aes(x = date, y = confirm), data = model_data) +
      ggplot2::scale_x_date(date_breaks = "1 week", date_labels = "%b %d") +
      ggplot2::theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      ggplot2::labs(
        x = "Time", y = paste("Weekly projection of confirmed \ncases starting from", max(cur_time_period_result$model_data_date), sep = " "),
        fill = "", color = ""
      )
  }
  return(p)
}


#' Sample from a truncated normal using inverse transform uniform sampling
#'
#'
#' @param  n Number of random samples
#' @param mean Mean of distribution
#' @param sd Standard deviation of distribution
#' @param lower_lim Lower limit for truncation
#'
rtrunc_norm <- function(n, mean = 0, sd = 1, lower_lim = 0) {
  lower_lim <- stats::pnorm(lower_lim, mean = mean, sd = sd)
  samples <- stats::qnorm(stats::runif(n, lower_lim, 1), mean = mean, sd = sd)
  return(samples)
}


#' Helper function to filter and extract first reliable date
#' @param data weekly transformed PLOVER or PHRDW data
#' @param min_cases minimum number of reliable cases for EpiEstim from config file
filter_dates <- function(data, min_cases) {
  confirm <- NULL
  data <- data %>%
    dplyr::filter(confirm >= min_cases) %>%
    dplyr::pull(date)
  return(data)
}

#' Format summary table for ViroReportR report
#' @param time_period_result output from  \code{forecast_time_period}
#' @return Formatted data.table summary table with wide format for coverage
#'
summary_ind_quantiles_formatter <- function(time_period_result) {
  `Confirmed cases` <- `Predicted cases` <- `50 percentile interval bounds` <- `95 percentile interval bounds` <- `Weekly date` <- weekly_date <- NULL
  coverage <- `.` <- `50 percentile interval` <- `95 percentile interval` <- EpiWeek <- NULL
  summary_table <- summary.forecast_time_period(time_period_result, pred_horizon_str = "1 week ahead")
  summary_individual_quantiles <- summary_table$individual_quantiles
  summary_individual_quantiles <- summary_individual_quantiles %>%
    dplyr::count(`Confirmed cases`, `Predicted cases`, `50 percentile interval bounds`, `95 percentile interval bounds`, coverage) %>%
    tidyr::pivot_wider(
      names_from = "coverage",
      values_from = "n",
      id_cols = c(
        "Confirmed cases", "Predicted cases", "50 percentile interval bounds",
        "95 percentile interval bounds", "weekly_date"
      )
    ) %>%
    replace(is.na(.), 0) %>%
    dplyr::mutate_if(is.numeric, round) %>%
    dplyr::mutate(`95 percentile interval` = ifelse(`50 percentile interval` == 1, 1,
      `95 percentile interval`
    )) %>%
    dplyr::mutate_at(
      dplyr::vars(`50 percentile interval`, `95 percentile interval`),
      dplyr::funs(case_when(
        . == 0 ~ emojifont::emoji(emojifont::search_emoji("x"))[28],
        . == 1 ~ emojifont::emoji(emojifont::search_emoji("check"))[1]
      ))
    ) %>%
    dplyr::mutate(EpiWeek = lubridate::epiweek(weekly_date)) %>%
    dplyr::rename("Weekly date" = weekly_date) %>%
    dplyr::select(
      EpiWeek, `Weekly date`, `Confirmed cases`, `Predicted cases`, `50 percentile interval`, `95 percentile interval`,
      `50 percentile interval bounds`, `95 percentile interval bounds`
    )
  return(summary_individual_quantiles)
}


#' Extract current forecast metrics: forecast prediction, percentile interval and Rt value
#' @param time_period_result output from  \code{forecast_time_period}
#' @param iter number of MCMC iterations used to generate Rt posterior
#' @return dataframe of current forecast metrics
#'
forecast_metrics <- function(time_period_result, iter = 10) {
  cur_time_period_result <- time_period_result[[length(time_period_result)]]

  Rt_mean <- round(cur_time_period_result$R$`Mean(R)`[length(cur_time_period_result$R$`Mean(R)`)], 2)
  Rt_std <- cur_time_period_result$R$`Std(R)`[length(cur_time_period_result$R$`Std(R)`)]
  R_lower <- round(Rt_mean - 1.96 * Rt_std / sqrt(iter), 2)
  R_upper <- round(Rt_mean + 1.96 * Rt_std / sqrt(iter), 2)

  if("forecast_res_quantiles" %in% names(time_period_result)){
    data_proj <- time_period_result$forecast_res_quantiles %>%
      dplyr::mutate_if(is.numeric, round) %>%
      dplyr::mutate(`95 percentile interval` = glue::glue("{p025}-{p975}")) %>%
      dplyr::mutate(`50 percentile interval` = glue::glue("{p25}-{p75}"))
  }else{
    data_proj <- tibble::tibble(
      date = cur_time_period_result$week_date,
      sim = cur_time_period_result$sim,
      incidence = cur_time_period_result$weekly_incidence,
    )
    data_proj <- data_proj %>%
      dplyr::mutate(incidence = incidence) %>%
      create_quantiles(date, variable = "incidence") %>%
      dplyr::mutate_if(is.numeric, round) %>%
      dplyr::mutate(`95 percentile interval` = glue::glue("{p025}-{p975}")) %>%
      dplyr::mutate(`50 percentile interval` = glue::glue("{p25}-{p75}"))
  }


  Rt_interval <- glue::glue("{R_lower}-{R_upper}")

  return(list(
    Rt_mean = Rt_mean,
    Rt_interval = Rt_interval,
    prediction = unname(data_proj$p50[1]),
    interval_90 = data_proj$`95 percentile interval`,
    interval_50 = data_proj$`50 percentile interval`,
    forecast_date = unname(format(as.Date(data_proj$date[1])))
  ))
}



#' Print out text output for ViroReportR report detailing current number of case visits, last value of Rt and corresponding intervals
#' @param time_period_result output from  \code{forecast_time_period}
#' @param ... optional arguments to be passed on to \code{forecast_metrics}
#' @return current forecast metrics
current_forecast_text <- function(time_period_result, ...) {
  forecast_metrics <- forecast_metrics(time_period_result, ...)
  cat(
    "The 1-week ahead forecast value of confirmed cases for", format(as.Date(forecast_metrics$forecast_date)),
    "is:", forecast_metrics$prediction, "cases/week \n\n",
    "The 95 % prediction interval for this forecast is", glue::glue("({forecast_metrics$interval_90[1]})"),
    "\n\n The 50 % prediction interval for this forecast is", glue::glue("({forecast_metrics$interval_50[1]})"),
    "\n\n The last estimated Rt value with the 95% confidence interval is:", forecast_metrics$Rt_mean, glue::glue("({forecast_metrics$Rt_interval})")
  )
}



#' Calculate bootstrapped standard smoothing error
#' @param time_period_result output from  \code{forecast_time_period}
#' @param data *data frame* at each time-step containing two columns: date and confirm (number of cases per day)
#' @return bootstrapped smoothing error for each sliding window
boot_smoothing_error <- function(time_period_result, data) {
  time_index <- seq(from = 1, to = length(time_period_result))
  time_period_original <- lapply(time_index, function(tp) {
    confirm <- time_period_result[[tp]]$confirm
    smoothed_confirm <- time_period_result[[tp]]$smoothed_confirm
    resid <- confirm - smoothed_confirm
    se_estimate <- mean(bootstrap::bootstrap(resid,
      nboot = 1000, sd
    )$thetastar)
  })
  sd_dat <- do.call(rbind.data.frame, time_period_original)
  return(sd_dat)
}


#' @noRd
check_data_contains_start_date <- function(data,start_date){
  if(!(as.Date(start_date) %in% as.Date(data$date))){
    stop("Data must include the `start_date`")
  }
}

#' Validates that the input `data` contains the required columns for use with
#'  EpiEstim.
#'
#' This function checks that the input data frame has the required columns:
#' `"date"` and `"confirm"`.
#' If either of these columns is missing, the function will stop with an
#' error message.
#'
#' @param data A data frame
#'
#' @noRd
check_epiestim_format <- function(data){
  required_columns <- c("date","confirm")
  missing_columns <- setdiff(required_columns, colnames(data))
  extra_columns <- setdiff(colnames(data),required_columns)
  if(length(missing_columns) > 0){
    stop("Data needs columns: ", paste(missing_columns, collapse = ", "))
  }
  if(length(extra_columns) > 0){
    stop("Data has redundant columns: ", paste(extra_columns, collapse = ", "))
  }
}

#' Ensure that the input `data` includes at least 14 valid days.
#'
#' This function verifies that the input data frame contains a minimum of
#' 14 days of records. Days at the start with zero confirmed cases are not
#' included in the count.
#'
#' @param data A data frame
#'
#' @noRd
check_min_days <- function(data){
  if(nrow(data) < 14){
    stop("At least 14 days of data are needed.")
  }
}
