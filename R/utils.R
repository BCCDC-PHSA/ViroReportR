#' Extract daily forecast samples
#'
#'
#' @description Function to produce short-term daily projections from objects of class {\code{\link[EpiEstim]{estimate_R}}}
#'
#' @param data *data frame* containing two columns: date and confirm (number of cases per day)
#' @param model_fit Object of class {\code{\link[EpiEstim]{estimate_R}}} generated by running \code{fit_epiestim_model}
#' @param dt *Integer* Number of days aggregated (set to 7 by default for weekly data aggregate)
#' @param n_days 	The number of days to run simulations for. Defaults to 14
#' @param n_sim The number of epicurves to simulate. Defaults to 1000
#'
#'
#'
#'
#' @return Data-frame of daily forecast samples from all simulations
#' \describe{
#'   \item{date}{date}
#'   \item{incidence}{projected number of daily confirmed cases}
#'   \item{sim}{simulation run number}
#' }

extract_daily_samples_epiestim_fit <- function(data, model_fit, dt = 7L, n_days = 14, n_sim = 1000) {
  if (isFALSE(is.data.frame(data)) | isFALSE(colnames(data) %in% c("date", "confirm"))) {
    stop("Must pass a data frame with two columns: date and confirm")
  }
  confirm <- NULL
  if (dt > 1L) {
  model_data_linelist <-
    tibble::tibble(
      date = seq(min(data$date),
        max(data$date) + lubridate::days(dt - 1),
        by = "1 day"
      ),
      confirm = model_fit$I
    ) %>%
    dplyr::group_by(date) %>%
    dplyr::reframe(case_index = seq(1:confirm))
  } else if (dt == 1L) {
    model_data_linelist <-
    tibble::tibble(
      date = model_fit$dates,
      confirm = model_fit$I
    )
  }
  incidence_obj <- incidence::incidence(model_data_linelist$date)

  r_vals <- utils::tail(model_fit$R, n = 1)
  r_dist <- rtrunc_norm(1000, mean = r_vals$`Mean(R)`, sd = r_vals$`Std(R)`, lower_lim = 0)

  # Use the project function
  proj <- projections::project(incidence_obj,
    R = r_dist,
    si = model_fit$si_distr[-1],
    n_sim = n_sim,
    n_days = n_days,
    R_fix_within = FALSE
  )


  data_proj <- as.data.frame(proj, long = TRUE)

  return(data_proj)
}



#' summarise a data frame `d` by groups along a `variable`
#' @param d tibble data frame
#' @param ... group_by variables
#' @param variable string
#'
#'
#' @return Data frame containing sample quantiles at probabilities 0.05, 0.25, 0.50,
#' 0.75 and 0.95

create_quantiles <- function(d, ..., variable = NULL) {
  d %>%
    dplyr::group_by(...) %>%
    dplyr::summarise(
      p50 = stats::quantile(.data[[variable]], 0.5),
      p25 = stats::quantile(.data[[variable]], 0.25),
      p75 = stats::quantile(.data[[variable]], 0.75),
      p025 = stats::quantile(.data[[variable]], 0.025),
      p975 = stats::quantile(.data[[variable]], 0.975),
      min_sim = min(.data[[variable]]),
      max_sim = max(.data[[variable]])
    )
}

#' Summarise incidence values into weekly aggregate
#' @param samples Daily samples generated from \code{extract_daily_samples_epiestim_fit}
#'
#' @return Data-frame of aggregated weekly forecast samples for each simulation run
#' \describe{
#'   \item{week_date}{last date of week over which daily samples were aggregated}
#'   \item{daily_sim}{simulation run number}
#'   \item{weekly_value}{projected number of daily confirmed cases aggregated by week}
#' }
extract_agg_samples_epiestim_fit <- function(samples) {
  daily_incidence <- week_date <- sim <- daily_date <- NULL
  samples <- samples %>%
    dplyr::mutate(week_date = lubridate::floor_date(daily_date, unit = "weeks")) %>%
    dplyr::group_by(week_date, sim) %>%
    dplyr::summarise(weekly_incidence = sum(daily_incidence), .groups = "keep")

  return(samples)
}


#' extract model data with extension during each iteration of loop
#'
#' @param data *data frame* containing two columns: date and confirm (number of cases per day)
#' @param min_model_date_str start date (in str)
#' @param extension_interval an integer (# of days)
#'
#'
#' @return input model_data subset to extension interval period specified



extend_rows_model_data <- function(data, min_model_date_str,
                                   extension_interval = 1) {
  data <- data %>%
    dplyr::arrange(date)
  min_model_date <- lubridate::ymd(min_model_date_str)

  if (extension_interval > 0) {
    max_model_date <- data$date[which(data$date == min_model_date) + extension_interval]
  }
  model_data <- data %>%
    filter(date >= min_model_date, date <= max_model_date)

  return(model_data)
}



#' Extract calculated quantiles from the weekly samples
#'
#' @param tp element from list output generated by \code{forecast_time_period}
#'


extract_quantile_epiestim <- function(tp) {
  dat_quantiles <-
    tibble::tibble(
      quantile_date = tp$quantile_date,
      p50 = tp$p50,
      p25 = tp$p25,
      p75 = tp$p75,
      p025 = tp$p025,
      p975 = tp$p975,
      min_sim = tp$min_sim,
      max_sim = tp$max_sim
    )
  return(dat_quantiles)
}




# Extract simulated samples

#' Extract simulated samples ideally 1000 samples per date
#'
#' @param tp element from list output generated by \code{forecast_time_period}
#' @param aggregate_unit Time forecasted samples are aggregated by (weekly or daily)
#'



extract_sim_samples_epiestim <- function(tp, aggregate_unit = NULL) {
  if (aggregate_unit == "weekly") {
    dat_samples <- tibble::tibble(
      quantile_date = tp$week_date,
      value = tp$weekly_incidence
    )
  } else if (aggregate_unit == "daily") {
    dat_samples <- tibble::tibble(
      quantile_date = tp$daily_date,
      value = tp$daily_incidence
    )
  }
  return(dat_samples)
}



#' Helper function to plot forecasts at each iteration with uncertainty quantile ranges
#'
#'
#' @param  cur_time_period_result element from list output generated by \code{forecast_time_period_epiestim}
#'
#' @return Plot displaying forecast for one time period

plot_all_time_period_forecast_data_helper <- function(cur_time_period_result) {
  p025 <- p975 <- p25 <- p75 <- p50 <- confirm <- incidence <- NULL
  model_data <- tibble::tibble(
    date = cur_time_period_result$model_data_date,
    confirm = cur_time_period_result$confirm
  )

  model_data <- model_data %>%
    filter(date > date[which.max(date) - 20])

  aggregate_unit <- cur_time_period_result$quantile_unit
  if (aggregate_unit == "weekly") {
    data_proj <- tibble::tibble(
      date = cur_time_period_result$week_date,
      sim = cur_time_period_result$sim,
      incidence = cur_time_period_result$weekly_incidence
    )
    p <- data_proj %>%
      dplyr::mutate(incidence = incidence) %>%
      create_quantiles(date, variable = "incidence") %>%
      ggplot2::ggplot(ggplot2::aes(x = date)) +
      ggplot2::theme_bw() +
      ggplot2::geom_ribbon(ggplot2::aes(ymin = p025, ymax = p975), fill = "#08519C", alpha = 0.25) +
      ggplot2::geom_ribbon(ggplot2::aes(ymin = p25, ymax = p75), fill = "#08519C", alpha = 0.25) +
      ggplot2::geom_line(ggplot2::aes(y = p50), color = "#08519C") +
      ggplot2::geom_point(ggplot2::aes(x = date, y = confirm), data = model_data) +
      ggplot2::scale_x_date(date_breaks = "1 week", date_labels = "%b %d") +
      ggplot2::theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      ggplot2::labs(
        x = "Time", y = paste("Weekly projection of confirmed \ncases starting from", max(cur_time_period_result$model_data_date), sep = " "),
        fill = "", color = ""
      )
  } else if (aggregate_unit == "daily") {
    data_proj <- tibble::tibble(
      date = cur_time_period_result$daily_date,
      sim = cur_time_period_result$sim,
      incidence = cur_time_period_result$daily_incidence
    )
    p <- data_proj %>%
      dplyr::mutate(incidence = incidence) %>%
      create_quantiles(date, variable = "incidence") %>%
      ggplot2::ggplot(ggplot2::aes(x = date)) +
      ggplot2::theme_bw() +
      ggplot2::geom_ribbon(ggplot2::aes(ymin = p025, ymax = p975), fill = "#08519C", alpha = 0.25) +
      ggplot2::geom_ribbon(ggplot2::aes(ymin = p25, ymax = p75), fill = "#08519C", alpha = 0.25) +
      ggplot2::geom_line(ggplot2::aes(y = p50), color = "#08519C") +
      ggplot2::geom_point(ggplot2::aes(x = date, y = confirm), data = model_data) +
      ggplot2::scale_x_date(date_breaks = "1 week", date_labels = "%b %d") +
      ggplot2::theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      ggplot2::labs(
        x = "Time", y = paste("Weekly projection of confirmed \ncases starting from", max(cur_time_period_result$model_data_date), sep = " "),
        fill = "", color = ""
      )
  }
  return(p)
}


#' Sample from a truncated normal using inverse transform uniform sampling
#'
#'
#' @param  n Number of random samples
#' @param mean Mean of distribution
#' @param sd Standard deviation of distribution
#' @param lower_lim Lower limit for truncation
#'

rtrunc_norm <- function(n, mean = 0, sd = 1, lower_lim = 0) {
  lower_lim <- stats::pnorm(lower_lim, mean = mean, sd = sd)
  samples <- stats::qnorm(stats::runif(n, lower_lim, 1), mean = mean, sd = sd)
  return(samples)
}


#' Helper function to extract dataframe with week ahead forecasts for Violin plot
#'
#' @param tp element from list output generated by \code{forecast_time_period_epiestim}
#' @param aggregate_unit  Time forecasted samples are aggregated by (weekly or daily)
#'
#'
#' @return Dataframe of forecasts at a single time-point (single element from list input)
#' \describe{
#'   \item{date}{daily date or weekly date over which samples were aggregated}
#'   \item{p50}{median quantile value}
#'   \item{p25}{quantile value of probability 0.25}
#'   \item{p75}{quantile value of probability 0.75}
#'   \item{p025}{quantile value of probability 0.05}
#'   \item{p975}{quantile value of probability 0.95}
#'   \item{pred_horizon}{Prediction time horizon (time period ahead for which prediction was made)}
#'   \item{value}{prediction values from simulated draws}
#' }
#'
pred_samples_with_quantile_helper <- function(tp, aggregate_unit = NULL) {
  value <- quantile_date <- daily_value <- NULL
  cur_samples_with_quantile <- extract_quantile_epiestim(tp)
  seq_time_length <- seq_len(nrow(cur_samples_with_quantile))
  if (aggregate_unit == "weekly") {
    cur_samples_with_quantile$pred_horizon <- paste(seq_time_length, "week ahead")
    cur_samples_with_week_date <- extract_sim_samples_epiestim(tp, aggregate_unit = eval(parse(text = "aggregate_unit")))
    cur_samples_with_quantile <- cur_samples_with_quantile %>%
      dplyr::left_join(cur_samples_with_week_date, by = "quantile_date") %>%
      dplyr::rename(sim_draws = value, weekly_date = quantile_date)
  } else if (aggregate_unit == "daily") {
    cur_samples_with_quantile$pred_horizon <- paste(seq_time_length, "days ahead")
    cur_samples_with_daily_date <- extract_sim_samples_epiestim(tp, aggregate_unit = eval(parse(text = "aggregate_unit")))
    cur_samples_with_quantile <- cur_samples_with_quantile %>%
      dplyr::left_join(cur_samples_with_daily_date, by = "quantile_date") %>%
      dplyr::rename(sim_draws = daily_value, daily_date = quantile_date)
  }

  return(cur_samples_with_quantile)
}


#' Extract data-frame with forecasts for validation violin plot
#'
#' @param time_period_result output from  \code{forecast_time_period}
#'
#' @return Data frame with forecasts at all time-points
#' #' \describe{
#'   \item{date}{daily date or weekly date over which samples were aggregated}
#'   \item{p50}{median quantile value}
#'   \item{p25}{quantile value of probability 0.25}
#'   \item{p75}{quantile value of probability 0.75}
#'   \item{p025}{quantile value of probability 0.05}
#'   \item{p975}{quantile value of probability 0.95}
#'   \item{pred_horizon}{Prediction time horizon (time period ahead for which prediction was made)}
#'   \item{value}{prediction values from simulated draws}
#' }
#'

create_forecast_df <- function(time_period_result) {
  results <- lapply(time_period_result, function(i) {
    pred_samples_with_quantile_helper(tp = i, aggregate_unit = time_period_result[[1]][["quantile_unit"]])
  })
  results <- do.call(rbind.data.frame, results)
  return(results)
}


#' Extract combined dataframe with forecast quantiles and weekly case data for summary function
#' @param forecast_dat output from  \code{create_forecast_df}
#' @param data *data frame* containing two columns: date and confirm (number of cases per week)
#' @param pred_horizon_str *string* prediction horizon time period to plot
#' @return combined dataframe with forecast quantiles and weekly case data for summary function
#' #' \describe{
#'   \item{date}{daily date or weekly date over which samples were aggregated}
#'   \item{p50}{median quantile value}
#'   \item{p25}{quantile value of probability 0.25}
#'   \item{p75}{quantile value of probability 0.75}
#'   \item{p025}{quantile value of probability 0.025}
#'   \item{p975}{quantile value of probability 0.975}
#'   \item{pred_horizon}{Prediction time horizon (time period ahead for which prediction was made)}
#'   \item{sim_draws}{prediction values from simulated draws}
#'   \item{min_sim}{minimum value of simulated predictions for week}
#'   \item{max_sim}{maximum value of simulated predictions for week}
#'   \item{confirm}{confirmed weekly cases}
#' }
#'
combine_df_pred_case <- function(forecast_dat, data, pred_horizon_str = NULL) {
  weekly_date <- sim_draws <- NULL
  data <- data %>% dplyr::slice(-c(1, 2))
  future_preds <- as.numeric(substr(pred_horizon_str, 0, 1))
  forecast_dat <- forecast_dat %>%
    dplyr::group_by(weekly_date) %>%
    dplyr::slice(1)
  index_future_pred <- c(rev(seq_len(nrow(forecast_dat)))[1:future_preds])
  forecast_dat <- forecast_dat[-index_future_pred, ]
  return(forecast_dat)
}

#' Extract squared error between predicted and confirmed case values weighted by number of time-points used to make prediction
#' @param confirm confirmed weekly cases
#' @param p50 prediction median quantile value
#' @param pred_horizon_str *string* prediction horizon time period to plot
#' @return *numeric* Weighted squared error at each data time-point
time_weighted_diff <- function(confirm, p50, pred_horizon_str = NULL) {
  future_preds <- as.numeric(substr(pred_horizon_str, 0, 1))
  squared_diff <- (confirm - p50)^2
  date_weights <- seq(from = future_preds + 1, to = length(confirm) + future_preds)
  weighted_squared_diff <- date_weights * squared_diff
  return(weighted_squared_diff)
}

#' Helper function to filter and extract first reliable date
#' @param data weekly transformed PLOVER or PHRDW data
#' @param min_cases minimum number of reliable cases for EpiEstim from config file
filter_dates <- function(data, min_cases) {
  confirm <- NULL
  data <- data %>%
    dplyr::filter(confirm >= min_cases) %>%
    dplyr::pull(date)
  return(data)
}

#' Extract common date that all diseases in PHRDW and PLOVER data can be reliably estimated with in EpiEstim
#' @param plover_list List of transformed PLOVER data (output of `get_all_vri_data`)
#' @param phrdw_list List of transformed PHRDW data (output of `get_all_vri_data`)
#' @param flua_min Minimum number of Flu-A cases required for reliable estimation by EpiEstim
#' @param flub_min Minimum number of Flu-B cases required for reliable estimation by EpiEstim
#' @param cov_min Minimum number of SARS-CoV2 cases required for reliable estimation by EpiEstim
#' @param rsv_min Minimum number of RSV cases required for reliable estimation by EpiEstim
#' @return *numeric* Weighted squared error at each data time-point
#'
common_reliable_estimation_date <- function(plover_list, phrdw_list,
                                            flua_min = config$min_nb_cases_flua,
                                            flub_min = config$min_nb_cases_flub,
                                            cov_min = config$min_nb_cases_covid,
                                            rsv_min = config$min_nb_cases_rsv) {
  config <- NULL
  disease_types <- c("flu_a", "flu_b", "sars_cov2", "rsv")
  min_cases_per_disease <- max(c(flua_min, flub_min, cov_min, rsv_min))

  flu_a <- format(as.Date(filter_dates(
    plover_list$flu_a,
    min_cases_per_disease
  )))
  flu_b <- format(as.Date(filter_dates(
    plover_list$flu_b,
    min_cases_per_disease
  )))
  covid <- format(as.Date(filter_dates(
    plover_list$sars_cov2,
    min_cases_per_disease
  )))
  rsv <- format(as.Date(filter_dates(
    plover_list$rsv,
    min_cases_per_disease
  )))

  common_plover_date <- min(Reduce(intersect, list(flu_a, flu_b, covid, rsv)))

  if (is.na(common_plover_date)) {
    common_plover_date <- c(min(flu_a), min(flu_b), min(covid), min(rsv))
  }


  flu_a <- format(as.Date(filter_dates(
    phrdw_list$flu_a,
    min_cases_per_disease
  )))
  flu_b <- format(as.Date(filter_dates(
    phrdw_list$flu_b,
    min_cases_per_disease
  )))
  covid <- format(as.Date(filter_dates(
    phrdw_list$sars_cov2,
    min_cases_per_disease
  )))
  rsv <- format(as.Date(filter_dates(
    phrdw_list$rsv,
    min_cases_per_disease
  )))

  common_phrdw_date <- min(Reduce(intersect, list(flu_a, flu_b, covid, rsv)))

  if (is.na(common_phrdw_date)) {
    common_phrdw_date <- c(min(flu_a), min(flu_b), min(covid), min(rsv))
  }

  return(list(common_phrdw_date = common_phrdw_date, common_plover_date = common_plover_date))
}

#' Format summary table for vriforecasting report
#' @param time_period_result output from  \code{forecast_time_period}
#' @return Formatted data.table summary table with wide format for coverage
#'
summary_ind_quantiles_formatter <- function(time_period_result) {
  `Confirmed cases` <- `Predicted cases` <- `50 percentile interval bounds` <- `95 percentile interval bounds` <- `Weekly date` <- weekly_date <- NULL
  coverage <- `.` <- `50 percentile interval` <- `95 percentile interval` <- EpiWeek <- NULL
  summary_table <- summary(time_period_result, pred_horizon_str = "1 week ahead")
  summary_individual_quantiles <- summary_table$individual_quantiles
  summary_individual_quantiles <- summary_individual_quantiles %>%
    dplyr::count(`Confirmed cases`, `Predicted cases`, `50 percentile interval bounds`, `95 percentile interval bounds`, coverage) %>%
    tidyr::pivot_wider(
      names_from = "coverage",
      values_from = "n",
      id_cols = c(
        "Confirmed cases", "Predicted cases", "50 percentile interval bounds",
        "95 percentile interval bounds", "weekly_date"
      )
    ) %>%
    replace(is.na(.), 0) %>%
    dplyr::mutate_if(is.numeric, round) %>%
    dplyr::mutate(`95 percentile interval` = ifelse(`50 percentile interval` == 1, 1,
                                                         `95 percentile interval`)) %>%
    dplyr::mutate_at(
      dplyr::vars(`50 percentile interval`, `95 percentile interval`),
      dplyr::funs(case_when(
        . == 0 ~ emojifont::emoji(emojifont::search_emoji("x"))[28],
        . == 1 ~ emojifont::emoji(emojifont::search_emoji("check"))[1]
      ))
    ) %>%
    dplyr::mutate(EpiWeek = lubridate::epiweek(weekly_date)) %>%
    dplyr::rename("Weekly date" = weekly_date) %>%
    dplyr::select(
      EpiWeek, `Weekly date`, `Confirmed cases`, `Predicted cases`, `50 percentile interval`, `95 percentile interval`,
      `50 percentile interval bounds`, `95 percentile interval bounds`
    )
  return(summary_individual_quantiles)
}


#' Extract current forecast metrics: forecast prediction, percentile interval and Rt value
#' @param time_period_result output from  \code{forecast_time_period}
#' @param iter number of MCMC iterations used to generate Rt posterior
#' @return dataframe of current forecast metrics
#'
forecast_metrics <- function(time_period_result, iter = 10) {
  cur_time_period_result <- time_period_result[[length(time_period_result)]]

  Rt_mean <- round(cur_time_period_result$R$`Mean(R)`[length(cur_time_period_result$R$`Mean(R)`)], 2)
  Rt_std <- cur_time_period_result$R$`Std(R)`[length(cur_time_period_result$R$`Std(R)`)]
  R_lower <- round(Rt_mean - 1.96 * Rt_std / sqrt(iter), 2)
  R_upper <- round(Rt_mean + 1.96 * Rt_std / sqrt(iter), 2)


  data_proj <- tibble::tibble(
    date = cur_time_period_result$week_date,
    sim = cur_time_period_result$sim,
    incidence = cur_time_period_result$weekly_incidence,
  )
  data_proj <- data_proj %>%
    dplyr::mutate(incidence = incidence) %>%
    create_quantiles(date, variable = "incidence") %>%
    dplyr::mutate_if(is.numeric, round) %>%
    dplyr::mutate(`95 percentile interval` = glue::glue("{p025}-{p975}")) %>%
    dplyr::mutate(`50 percentile interval` = glue::glue("{p25}-{p75}"))

  Rt_interval <- glue::glue("{R_lower}-{R_upper}")

  return(list(
    Rt_mean = Rt_mean,
    Rt_interval = Rt_interval,
    prediction = unname(data_proj$p50[1]),
    interval_90 = data_proj$`95 percentile interval`,
    interval_50 = data_proj$`50 percentile interval`,
    forecast_date = unname(format(as.Date(data_proj$date[1])))
  ))
}


#' Process PLOVER and PHRDW data for all respiratory diseases supported by vriforecasting
#' @param raw_plover_data PLOVER data
#' @param raw_phrdw_data PHRDW data
#' @return Lists of dataframes of transformed PLOVER and PHRDW data for each respiratory viral disease with columns `date` and `confirm`
get_all_vri_data <- function(raw_plover_data, raw_phrdw_data) {
  disease_types <- c("flu_a", "flu_b", "sars_cov2", "rsv")
  plover_list <- stats::setNames(
    lapply(disease_types, function(disease_type) {
      get_weekly_plover_by_date_type(plover_data = raw_plover_data, type = disease_type, start_date = "2021-09-01")
    }),
    disease_types
  )

  phrdw_list <- stats::setNames(
    lapply(disease_types, function(disease_type) {
      get_phrdw_by_type_date_age(phrdw_data = raw_phrdw_data, type = disease_type, start_date = "2021-09-01")
    }),
    disease_types
  )
  return(list(plover_list = plover_list, phrdw_list = phrdw_list))
}


#' Print out text output for vriforecasting report detailing current number of case visits, last value of Rt and corresponding intervals
#' @param time_period_result output from  \code{forecast_time_period}
#' @param ... optional arguments to be passed on to \code{forecast_metrics}
#' @return current forecast metrics
current_forecast_text <- function(time_period_result, ...) {
  forecast_metrics <- forecast_metrics(time_period_result, ...)
  cat(
    "The 1-week ahead forecast value of confirmed cases for", format(as.Date(forecast_metrics$forecast_date)),
    "is:", forecast_metrics$prediction, "cases/week \n\n",
    "The 95 % prediction interval for this forecast is", glue::glue("({forecast_metrics$interval_90[1]})"),
    "\n\n The 50 % prediction interval for this forecast is", glue::glue("({forecast_metrics$interval_50[1]})"),
    "\n\n The last estimated Rt value with the 95% confidence interval is:", forecast_metrics$Rt_mean, glue::glue("({forecast_metrics$Rt_interval})")
  )
}



#' Print out text output for vriforecasting report detailing validation information including proportion of predictions in 50% and 95% intervals
#' @param time_period_result output from  \code{forecast_time_period}
#' @return current forecast metrics
validation_summary_text <- function(time_period_result) {
  summary_table_quantiles <- summary(time_period_result, pred_horizon_str = "1 week ahead")
  proportion_95 <- summary_table_quantiles$quantile_summary$proportion[2]
  proportion_50 <- summary_table_quantiles$quantile_summary$proportion[1]
  frac_95 <- glue::glue("({summary_table_quantiles$quantile_summary$counts[2]}/{sum(summary_table_quantiles$quantile_summary$counts)})")
  frac_50 <- glue::glue("({summary_table_quantiles$quantile_summary$counts[1]}/{sum(summary_table_quantiles$quantile_summary$counts)})")
  mspe <- summary_table_quantiles$time_weighted_mspe
  cat(
    "Previous 1-week ahead forecasts had", proportion_50, "%", frac_50, "of the true confirmed cases within the 50% prediction interval",
    "and", proportion_95, "%", frac_95, "of the true confirmed cases in the 95% prediction interval \n",
    "\n\n The Mean squared percentage error on the validation set is:", mspe, "\n"
  )
}



#' Print out text output for vriforecasting report detailing validation information including proportion of predictions in 50% and 95% intervals
#' @param time_period_result output from  \code{forecast_time_period}
#' @param year_input *numeric* indicating the year to generate the validation summary
#' @return current forecast metrics
validation_summary_text_season <- function(time_period_result, year_input = 2021) {
  summary_table_quantiles <- summary_season(time_period_result, pred_horizon_str = "1 week ahead", year = year_input)
  proportion_95 <- summary_table_quantiles$quantile_summary$proportion[2]
  proportion_50 <- summary_table_quantiles$quantile_summary$proportion[1]
  frac_95 <- glue::glue("({summary_table_quantiles$quantile_summary$counts[2]}/{sum(summary_table_quantiles$quantile_summary$counts)})")
  frac_50 <- glue::glue("({summary_table_quantiles$quantile_summary$counts[1]}/{sum(summary_table_quantiles$quantile_summary$counts)})")
  mspe <- summary_table_quantiles$time_weighted_mspe
  cat(
    "In the", year_input, "season,", "Previous 1-week ahead forecasts had", proportion_50, "%", frac_50, "of the true confirmed cases within the 50% prediction interval",
    "and", proportion_95, "%", frac_95, "of the true confirmed cases in the 95% prediction interval \n",
    "\n\n The Mean squared percentage error on the validation set is:", mspe, "\n"
  )
}

#' Get proportion of cases below minimum in confirmed case data numbers as deterministic check for forecast quality
#' @param data *data frame* at each time-step containing two columns: date and confirm (number of cases per day)
#' @param model_data input dataframe containing two columns: date and confirm (number of cases per day)
#' @return numeric proportion of zeroes

forecast_quality_precheck <- function(data, model_data) {
  data <- tail(data)
return(sum(data$confirm > median(model_data$confirm))/nrow(data))
}

#' Plot Mean Rt with time index (dates)
#' @param time_period_result output from  \code{forecast_time_period}
#' @return Mean Rt with time index plot

plot_rt <- function(time_period_result) {
  last_time_period <- time_period_result[[length(time_period_result)]]
  model_data_dates <- last_time_period$model_data_date
  rt_dat <- last_time_period[["R"]]
  rt_start_date <- model_data_dates[1]
  rt_date_seq <- seq(rt_start_date, by = "day", length.out = length(rt_dat$t_start))
  rt_dat$date <-  rt_date_seq
  rt_dat <- rt_dat %>% dplyr::mutate(
    weekly_date = lubridate::floor_date(date, unit = "week")
  ) %>%
    dplyr::group_by(weekly_date) %>%
    dplyr::summarise(weekly_rt = mean(`Mean(R)`), weekly_ymin = mean(`Quantile.0.025(R)`),
                     weekly_ymax = mean(`Quantile.0.975(R)`))
p <- ggplot(rt_dat, aes(x = weekly_date)) +
  ggplot2::geom_ribbon(ggplot2::aes(ymin = weekly_ymin, ymax = weekly_ymax), fill = "#08519C", alpha = 0.25) +
<<<<<<< HEAD
  ggplot2::geom_line(ggplot2::aes(y = weekly_rt), color = "#08519C") + theme_bw() + labs(x = "Time", y = "mean(expression(R[t]))")
=======
  ggplot2::geom_line(ggplot2::aes(y = weekly_rt), color = "#08519C") + theme_bw() + labs(x = "Time", y = "Mean(Rt)")
>>>>>>> a419c0413360a491032112d6adcb12d37ccb8282
 return(p)
}

#' Calculate bootstrapped standard smoothing error
#' @param time_period_result output from  \code{forecast_time_period}
#' @param data *data frame* at each time-step containing two columns: date and confirm (number of cases per day)
#' @return bootstrapped smoothing error for each sliding window
boot_smoothing_error <- function(time_period_result, data) {
  start_date <- time_period_result[[1]]$model_data_date[1]
  start_index <- which(data$date == lubridate::ymd(start_date))
  time_length <- nrow(data) - start_index
  time_index <- seq_len(time_length)
  time_period_original <- lapply(time_index, function(tp) {
    model_data <- extend_rows_model_data(
      data = data, min_model_date_str = start_date,
      extension_interval = tp)
    model_data$smoothed_confirm <- time_period_result[[tp]]$smoothed_confirm
    model_data$resid <- model_data$confirm- model_data$smoothed_confirm
    model_data$se_estimate <- mean(bootstrap::bootstrap(model_data$resid,
                  nboot = 1000, sd)$thetastar)
     })
  sd_dat <- do.call(rbind.data.frame, time_period_original)
  names(sd_dat) <- "smoothing_error"
  filtered_data <- data %>%
    dplyr::arrange(date) %>%
    dplyr::filter(date > start_date) %>%
    dplyr::filter(date > date[1])

  next_date <- filtered_data %>%
    dplyr::arrange(date) %>%
    dplyr::mutate(new_date = date + 7)
  next_date <- next_date$new_date[nrow(next_date)]

   sd_dat_date <- c(filtered_data$date, next_date)
   sd_dat$weekly_date <- sd_dat_date
   return(sd_dat)
}



#' Calculate 95% prediction interval bounds for smoothed predictions
#' @param time_period_result output from  \code{forecast_time_period}
#' @param data original input *data frame* at each time-step containing two columns: date and confirm (number of cases per day)
#' @return upper and lower bounds for 95% prediction interval for smoothed predictions
pred_interval_forecast <- function(time_period_result, data) {
  smoothing_error_dat <- boot_smoothing_error(time_period_result, data)
  forecast_dat <- create_forecast_df(time_period_result)
  smoothing_error_dat_copy <- forecast_dat %>%
    dplyr::group_by(weekly_date) %>%
    dplyr::summarise(n = n())
  smoothing_error_dat_copy  <- smoothing_error_dat_copy   %>%
    left_join(smoothing_error_dat, by = c("weekly_date")) %>%
    mutate(smoothing_error = ifelse(is.na(smoothing_error),
                                    smoothing_error[nrow(smoothing_error_dat_copy)-1],
                                    smoothing_error))

 forecast_dat <- forecast_dat %>%
   dplyr::left_join(smoothing_error_dat_copy, by = "weekly_date") %>%
   dplyr::group_by(weekly_date) %>%
   dplyr::mutate(mean_sim = mean(sim_draws)) %>%
   dplyr::mutate(upper_bound90 = mean_sim + qnorm(1-0.025)*(sd(sim_draws)/sqrt(n()) + smoothing_error)) %>%
   dplyr::mutate(lower_bound90 = mean_sim - qnorm(1-0.025)*(sd(sim_draws)/sqrt(n()) + smoothing_error)) %>%
   dplyr::mutate(upper_bound50 = mean_sim + qnorm(1-0.25)*(sd(sim_draws)/sqrt(n()) + smoothing_error)) %>%
   dplyr::mutate(lower_bound50 = mean_sim - qnorm(1-0.25)*(sd(sim_draws)/sqrt(n()) + smoothing_error)) %>%
   dplyr::mutate(lower_bound90 = ifelse(lower_bound90 < 0, 0, lower_bound90)) %>%
   dplyr::mutate(lower_bound50 = ifelse(lower_bound50 < 0, 0, lower_bound50))
 return(forecast_dat)
}

